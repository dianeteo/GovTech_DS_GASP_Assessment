{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77b3f484",
   "metadata": {},
   "source": [
    "# 2. Proposed Approaches for Classification/Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a1cba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98da6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "recruitment_df_processed = pd.read_csv('recruitment_df_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ba2b00",
   "metadata": {},
   "source": [
    "As stated earlier, the dataset is a highly imbalanced dataset with only 5% of observations being tagged as fraudulent. Given this imbalance, we deal with it at the model level using class weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2707c6",
   "metadata": {},
   "source": [
    "## 2A. Classification Models with Features and Empirical Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4273c44",
   "metadata": {},
   "source": [
    "The baseline model for this classification/fraud detection model would be to use the features given in the dataset together with a list of empirical rules to train a baseline classification model, specifically a Logistic Regression model.\n",
    "\n",
    "Given that through EDA, we found out that given features such as required experience, required education and whether the job advertisement had a company profile/logo/screening questions were different between fraudulent job advertisements and non-fraudulent ones, the natural step would be to use these features as regressors. We also found out that derived features such as the length of company profile, description and requirements, together with other signals like money in description, money in title, had significant differences between fraudulent and non-fraudulent job advertisements, so we include these features as well in the logistic regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3110e5",
   "metadata": {},
   "source": [
    "### Preparing Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9846c020",
   "metadata": {},
   "source": [
    "List of features used:\n",
    "1. Binary Features: `has_company_profile`, `has_company_logo`, `has_questions`, `money_in_desc`, `money_in_title`, `url_in_description`, `consecutive_punct`\n",
    "2. Categorical Features: `employment_type`, `required_experience`, `required_education`\n",
    "3. Numerical Features: `company_profile_len`, `description_len`, `requirements_len`\n",
    "\n",
    "These features have been generated above in the EDA stage and the code below prepares the features for model training (e.g. converting all binary features to '1's and '0's)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b736a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = recruitment_df_processed.copy()\n",
    "\n",
    "df[\"fraud_target\"] = df[\"fraudulent\"].map({'t':1, 'f':0}).astype(int)\n",
    "\n",
    "# --- Feature groups ---\n",
    "bin_cols = [\"has_company_profile\", \"has_company_logo\", \"has_questions\", \n",
    "            \"money_in_desc\", \"money_in_title\", \n",
    "            \"url_in_description\", \"consecutive_punct\"]\n",
    "\n",
    "cat_cols = [\"employment_type\", \"required_experience\", \"required_education\", \"industry\"]\n",
    "\n",
    "num_cols = [\"company_profile_stripped_len\", \"description_stripped_len\", \"requirements_stripped_len\"]\n",
    "\n",
    "# --- Binary features: coerce to {0,1} ---\n",
    "to01 = {\n",
    "    True: 1, False: 0,\n",
    "    't': 1, 'f': 0, 'T': 1, 'F': 0,\n",
    "    'true': 1, 'false': 0, 'TRUE': 1, 'FALSE': 0,\n",
    "    '1': 1, '0': 0,\n",
    "    1: 1, 0: 0\n",
    "}\n",
    "for b in bin_cols:\n",
    "    df[b] = df[b].map(to01)\n",
    "    df[b] = df[b].fillna(0).astype(int) \n",
    "\n",
    "# --- Categorical features: fill NAs with \"Unknown\" ---\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].fillna(\"Unknown\")\n",
    "\n",
    "# --- Target ---\n",
    "y = df[\"fraud_target\"]\n",
    "\n",
    "# --- Preprocessing pipeline ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"bin\", \"passthrough\", bin_cols),  # already 0/1\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(class_weight=\"balanced\", max_iter=1000))\n",
    "])\n",
    "\n",
    "# --- Train/test split ---\n",
    "X = df[bin_cols + cat_cols + num_cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3013e2",
   "metadata": {},
   "source": [
    "## 2B. TF-IDF and Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc57754",
   "metadata": {},
   "source": [
    "While the previous classification model uses metadata features, term frequency-inverse document frequency captures the nuance of the job description, title, company profile and requirements. TF-IDF is a simplistic way of allowing the model to learn patterns from the writeups before proceeding to more advanced methods like word embeddings and using LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8a6c23",
   "metadata": {},
   "source": [
    "### Preparing Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f3a322",
   "metadata": {},
   "source": [
    "We have previously used BeautifulSoup to clean up the job description and here we also build a composite text where we append the job title, company profile, description and requirements together before fitting the term frequency-inverse document frequency transformation. We combine these text so that the logistic regression model can treat the entire advertisement as a single document. \n",
    "\n",
    "We also convert all text to lowercase to ensure that the model does not treat capitalised and non-capitalised words like \"Job\" and \"job\" as different tokens. This reduces sparsity and improves generalisation.\n",
    "\n",
    "We allow for the identification of frequent phrases as well, not just words i.e. allowing ngram_range=(1, 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db98002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build composite text (title + profile + description + requirements + benefits) ---\n",
    "text_cols = [\"title\", \"company_profile_stripped\", \"description_stripped\", \"requirements_stripped\", \"benefits_stripped\"]\n",
    "\n",
    "df[\"text_all\"] = (\n",
    "    df[text_cols]\n",
    "    .fillna(\"\")\n",
    "    .agg(\" \".join, axis=1)\n",
    "    .str.lower()   # lowercase everything\n",
    ")\n",
    "\n",
    "X_text = df[\"text_all\"]\n",
    "y = df[\"fraud_target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "126cde93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train/test split (stratified) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_text, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- TF-IDF + class-weighted Logistic Regression pipeline ---\n",
    "tfidf_lr = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        lowercase=True,          # lowercase everything \n",
    "        stop_words=\"english\",    # remove common stopwords\n",
    "        ngram_range=(1, 2),      # unigrams + bigrams catch short phrases\n",
    "        max_df=0.9,              # drop terms in >90% of docs (too common)\n",
    "        min_df=5,                # keep terms that appear in at least 5 docs\n",
    "        max_features=200         # cap dimensionality\n",
    "    )),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        class_weight=\"balanced\", # handle class imbalance at the model level\n",
    "        max_iter=2000,\n",
    "        solver=\"liblinear\"\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea64ba0f",
   "metadata": {},
   "source": [
    "The cell above vectorises the composite texts into a TF-IDF feature matrix and pipes it into a class weighted logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1fba68",
   "metadata": {},
   "source": [
    "## 2C. Combination of TF-IDF, Features and Empirical Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b090bed",
   "metadata": {},
   "source": [
    "In the following cell, we combine the TF-IDF vectorised scores, the standard features and the rule-based features. Through combining these features, we hope that the model's performance will be able to learn both the distinctive patterns in the text as well as non-linguistic features that TF-IDF cannot capture. \n",
    "\n",
    "Some limitations of combining both sets of features include the possibility that the high number of features in the TF-IDF vector might overshadow the structured features, which might cause the model to underweight the non-linguistic signals. If after running the model and we realise that this might be the case (through running feature importance), we can adjust the number of features in the TF-IDF vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90baab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Build X, y ----------\n",
    "text_col = \"text_all\"\n",
    "X = pd.concat([df[[text_col]], df[bin_cols + cat_cols + num_cols]], axis=1)\n",
    "y = df[\"fraud_target\"]\n",
    "\n",
    "# ---------- Preprocessor: text + categoricals + numerics + binaries ----------\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"txt\", TfidfVectorizer(\n",
    "            lowercase=True,\n",
    "            stop_words=\"english\",\n",
    "            ngram_range=(1, 2),\n",
    "            max_df=0.9,\n",
    "            min_df=5,\n",
    "            max_features=200\n",
    "        ), text_col),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"bin\", \"passthrough\", bin_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# ---------- Class-weighted Logistic Regression (combined model) ----------\n",
    "combined_lr = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        class_weight=\"balanced\",\n",
    "        max_iter=2000,\n",
    "        solver=\"liblinear\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "# ---------- Train/test split (stop here if only preparing) ----------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b584c715",
   "metadata": {},
   "source": [
    "## 2D. Word Embeddings and Transformer Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66c7dc5",
   "metadata": {},
   "source": [
    "For our last method, we embed the composite texts using transformer specific embedding models and train transformer models with these embeddings and the specific tag (fraud/non-fraudulent) and use transformer models to predict whether a specific job advertisement is fraudulent or not.\n",
    "\n",
    "We choose transformer models over large language models (LLMs) because transformers are smaller and more efficient to fine-tune on labeled data, which in this case we are working with labeled fraud data. Furthermore, encoder-only transformers use bidirectional attention mechanisms and are able to capture the linguistic patterns listed in the composite texts of job advertisements. LLMs are more suited for text generation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d21178",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d66be1",
   "metadata": {},
   "source": [
    "To prepare our data, we create the composite text field. This time, we do 3 things differently from before:\n",
    "1. We append tags to each component of the composite text. If the text belongs to the job title feature, we append `[JOB TITLE]` in front of the text and if the text belongs to the job description feature, we append `[JOB DESCRIPTION]` in front of the text. This helps the transformer model better understand the lingiustic patterns in the composite text. We don't do this for the TF-IDF model because these tags would inflate term frequency but not allow the TF-IDF model to pick up linguistic cues.\n",
    "2. We also include `required_education` and `required_experience` this time because the transformer model will be able to pick up these linguistic cues through its self-attention mechanism. In contrast to the data preparation for the TF-IDF vector, these would add to the term frequencies of specific words but will not have any linguistic significance. Hence we exclude it from the data preparation step above but include it in this approach.\n",
    "3. We do not convert all text to lowercase because RoBERTa is pretrained on cased text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f8ea2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all source fields used in the composite\n",
    "text_fields = [\n",
    "    \"title\", \"company_profile_stripped\", \"description_stripped\", \"requirements_stripped\",\n",
    "    \"benefits_stripped\", \"required_education\", \"required_experience\"\n",
    "]\n",
    "\n",
    "# Make empty categories explicit\n",
    "df[\"required_education\"]  = df[\"required_education\"].replace({\"\": \"Unknown\"}).fillna(\"Unknown\")\n",
    "df[\"required_experience\"] = df[\"required_experience\"].replace({\"\": \"Unknown\"}).fillna(\"Unknown\")\n",
    "\n",
    "# Use explicit section tags so the encoder gets structure cues\n",
    "df[\"text\"] = (\n",
    "    \"[JOB TITLE] \"          + df[\"title\"].str.strip() + \" \"\n",
    "    \"[COMPANY PROFILE] \"    + df[\"company_profile_stripped\"].str.strip() + \" \"\n",
    "    \"[JOB DESCRIPTION] \"    + df[\"description_stripped\"].str.strip() + \" \"\n",
    "    \"[JOB REQUIREMENTS] \"   + df[\"requirements_stripped\"].str.strip() + \" \"\n",
    "    \"[BENEFITS] \"           + df[\"benefits_stripped\"].str.strip() + \" \"\n",
    "    \"[REQUIRED EDUCATION] \" + df[\"required_education\"].str.strip() + \" \"\n",
    "    \"[REQUIRED EXPERIENCE] \"+ df[\"required_experience\"].str.strip()\n",
    ").str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "\n",
    "# Ensure text is clean strings\n",
    "df[\"text\"] = df[\"text\"].fillna(\"\").astype(str)\n",
    "df[\"label\"] = df[\"fraud_target\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47581c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 14304/14304 [00:04<00:00, 3570.15 examples/s]\n",
      "Map: 100%|██████████| 3576/3576 [00:01<00:00, 3406.71 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared RoBERTa tokenized datasets.\n",
      "Train examples: 14304  | Val examples: 3576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_text, X_val_text, y_train, y_val = train_test_split(\n",
    "    df[\"text\"], df[\"label\"], test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "# ======= RoBERTa-specific tokenization =======\n",
    "train_ds = Dataset.from_pandas(pd.DataFrame({\"text\": X_train_text.values, \"label\": y_train.values}))\n",
    "val_ds   = Dataset.from_pandas(pd.DataFrame({\"text\": X_val_text.values,   \"label\": y_val.values}))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "train_tok = train_ds.map(tokenize, batched=True, remove_columns=[\"text\"]).with_format(\"torch\")\n",
    "val_tok   = val_ds.map(tokenize,   batched=True, remove_columns=[\"text\"]).with_format(\"torch\")\n",
    "\n",
    "print(\"Prepared RoBERTa tokenized datasets.\")\n",
    "print(\"Train examples:\", len(train_tok), \" | Val examples:\", len(val_tok))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a77d6",
   "metadata": {},
   "source": [
    "## Evaluation of approaches 2A - 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156a02c7",
   "metadata": {},
   "source": [
    "Having chosen 2A as a baseline model, we can see whether subsequent approaches improve model performance. \n",
    "\n",
    "Given that the dataset is highly imbalanced with less than 5% of observations being tagged as fraudulent, in order to evaluate model performance, choosing accuracy as a metric would not be sufficient as a simplistic model that predicts non-fradulent for all observations will give an accuracy of ~95%. Hence I propose using metrics like `precision and recall` instead.\n",
    "\n",
    "In the case of fraud detection, while the cost of leaving up fraudulent job advertisements is higher than the cost of wrongly taking down non-fraudulent job advertisements (i.e. minimising false negatives are important), it is important to balance both precision and recall because if we only maximise on recall, there will be too many false positives.\n",
    "\n",
    "Hence we should maximise the F1-score, which balances out the importance of precision and recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d1e43f",
   "metadata": {},
   "source": [
    "After selecting the best performing model based on the F1-score, we will calibrate the classification threshold based on the `PR-AUC curve`, choosing the classification threshold that gives the highest AUC so as to ensure that our model balances between catching as many fraudulent job advertisements as possible (high recall) while minimising false alarms (high precision)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
